{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: How would you approach developing an AI system that maintains both accuracy and fairness in contexts where biased data may be prevalent?\n",
    "\n",
    "Ensuring Fairness and Accuracy in AI Systems with Biased Data: \n",
    "\n",
    "To develop an AI system that maintains accuracy while addressing potential bias, I would start by thoroughly examining the data for any existing biases and addressing them through techniques such as re-sampling, re-weighting, or data augmentation. I'd incorporate fairness constraints into the model's objectives to ensure that the system's decisions are balanced across different groups. Regular auditing and validation of the model against real-world outcomes would be essential to identify and correct any unintended bias. Also, I'd include stakeholders in the development process to ensure diverse perspectives and feedback.\n",
    "\n",
    "### Example Approach:\n",
    "\n",
    "1. Data Preprocessing and Bias Mitigation\n",
    "2. Algorithm Selection\n",
    "3. Fairness Metrics\n",
    "4. Human-in-the-Loop Approach\n",
    "5. Model Audits and Transparency\n",
    "\n",
    "Example of using a Random Forest Classifier on synthetic data, showing how we can evaluate accuracy and fairness using metrics like AUC and F1 Score.\n",
    "\n",
    "```python\n",
    "# Example Script: Fairness-aware classification using Random Forest and AUC score\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, random_state=42)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a simple Random Forest model\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate model performance\n",
    "y_pred = clf.predict(X_test)\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'AUC Score: {auc_score}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: How would you design a machine learning model to predict customer churn in the insurance industry?\n",
    "\n",
    "Designing a Customer Churn Prediction Model for the Insurance Industry: \n",
    "\n",
    "For predicting customer churn in the insurance sector, I'd leverage a combination of supervised learning techniques with advanced methods such as ensemble learning or gradient boosting, which are well-suited for handling imbalanced data. To address the sparsity of events, I would incorporate domain-specific features such as customer interactions, policy changes, and external data like economic indicators. Additionally, implementing techniques like SMOTE (Synthetic Minority Over-sampling Technique) could help balance the dataset, while cost-sensitive learning methods would ensure that the model effectively handles the unique challenges posed by the insurance domain's imbalanced nature.\n",
    "\n",
    "### Example Approach:\n",
    "\n",
    "1. Data Collection and Feature Engineering\n",
    "2. Handling Imbalanced Classes with SMOTE\n",
    "3. Model Selection (Random Forest)\n",
    "4. Evaluation Metrics (AUC, F1 Score)\n",
    "\n",
    "```python\n",
    "# Example Code: Handling Imbalanced Data using SMOTE and Random Forest\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic imbalanced dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, weights=[0.9, 0.1], random_state=42)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use SMOTE to handle the imbalance in the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Random Forest model on resampled data\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict and evaluate the model on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'AUC Score: {auc_score}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print('Classification Report:\\\\n', classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
